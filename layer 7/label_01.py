# -*- coding: utf-8 -*-
"""label - 01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ig5h-5c-YHFd3iwVlqDNlYxwvV0JRNI1
"""

# import libraries
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score, KFold
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import SelectKBest
from sklearn.model_selection import GridSearchCV

# read the test and train data files
train_df = pd.read_csv("train.csv")
valid_df = pd.read_csv("valid.csv")
test_df = pd.read_csv("test.csv")

"""label 01"""

train1_df = train_df.iloc[:,:-3]
valid1_df = valid_df.iloc[:, :-3]
test1_df = test_df.iloc[:, 1:]

train1_df.dropna(inplace=True)
valid1_df.dropna(inplace=True)
test1_df.dropna(inplace=True)

# splitting the test and train datasets into X and Y values
X1_train= train1_df.iloc[:,0:-1].values
Y1_train = train1_df.iloc[:,-1].values
X1_valid = valid1_df.iloc[:,0:-1].values
Y1_valid = valid1_df.iloc[:,-1].values
X1_test = test1_df.iloc[:,:].values

# scalling and fitting data
scaler = StandardScaler()
scaler.fit(X1_train)

X1_train = scaler.transform(X1_train)
X1_valid = scaler.transform(X1_valid)
X1_test = scaler.transform(X1_test)

classifiers = [
    ("Random Forest", RandomForestClassifier()),
    ("K-Nearest Neighbors", KNeighborsClassifier()),
    ("Support Vector Machine", SVC())
]

kf = KFold(n_splits=5, shuffle=True, random_state=42)  # You can change the shuffling and random state

# Iterate over each classifier and perform cross-validation
for clf_name, clf in classifiers:
    cross_val_scores = cross_val_score(clf, X_1_train, Y_1_train, cv=kf, scoring='accuracy')

    # Print the cross-validation scores for each classifier
    print(f"{clf_name} Cross-validation scores:", cross_val_scores)

    # Calculate and print the mean and standard deviation of the scores
    print(f"{clf_name} Mean accuracy:", cross_val_scores.mean())
    print(f"{clf_name} Standard deviation:", cross_val_scores.std())
    print("\n")

# Initialize and train a Support Vector Machine classifier
svm_classifier = SVC(kernel='linear', C=1.0)
svm_classifier.fit(X1_train, Y1_train)

# Make predictions on the test set
y_pred = svm_classifier.predict(X1_valid)

print(classification_report(Y1_valid, y_pred))

# Create a SelectKBest instance with a scoring function (e.g., chi-squared)
selector = SelectKBest(score_func=f_classif, k=250)  # Select the top 2 features

# Fit and transform your data to select the best k features
X1_best_train = selector.fit_transform(X1_train, Y1_train)
X1_best_valid = selector.transform(X1_valid)
X1_best_test = selector.transform(X1_test)

svm_classifier.fit(X1_best_train, Y1_train)

# Make predictions on the test set
y_pred = svm_classifier.predict(X1_best_valid)

print(classification_report(Y1_valid, y_pred))

pca=PCA(0.9)
pca = pca.fit(X1_best_train)

x_1_train_pca=pca.fit_transform(X1_best_train)
x_1_valid_pca = pca.transform(X1_best_valid)
x_1_test_pca = pca.transform(X1_best_test)

svm_classifier.fit(x_1_train_pca, Y1_train)

# Make predictions on the test set
y_pred = svm_classifier.predict(x_1_valid_pca)

print(classification_report(Y1_valid, y_pred))

x_1_train_pca.shape

param_grid = {
    'C': [0.1, 1, 10],  # Regularization parameter
    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type
    'gamma': ['scale', 'auto', 0.1, 1]  # Kernel coefficient for 'rbf' and 'poly'
}

# Create a GridSearchCV object with cross-validation
grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)

# Fit the GridSearchCV object to the data to find the best hyperparameters
grid_search.fit(x_1_train_pca, Y1_train)

# Print the best hyperparameters and corresponding accuracy
best_params = grid_search.best_params_
best_accuracy = grid_search.best_score_
print("Best Hyperparameters:", best_params)
print("Best Accuracy:", best_accuracy)

best_model = grid_search.best_estimator_
y_pred = best_model.predict(x_1_valid_pca)

print(classification_report(Y1_valid, y_pred))

"""label 02"""

