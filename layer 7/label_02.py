# -*- coding: utf-8 -*-
"""label - 02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hSvMzVWQ0WL4ee43mbTppwXJ4dxR-mHB
"""

# import libraries
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score, KFold
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import SelectKBest
from sklearn.model_selection import GridSearchCV
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression

# read the test and train data files
train_df = pd.read_csv("train.csv")
valid_df = pd.read_csv("valid.csv")
test_df = pd.read_csv("test.csv")

train2_df = train_df.iloc[:,:-2]
valid2_df = valid_df.iloc[:, :-2]
test2_df = test_df.iloc[:, 1:]

train2_df.drop(columns=["label_1"], inplace=True)
valid2_df.drop(columns=["label_1"], inplace=True)

train2_df.dropna(inplace=True)
valid2_df.dropna(inplace=True)
test2_df.dropna(inplace=True)

# splitting the test and train datasets into X and Y values
X2_train= train2_df.iloc[:,0:-1].values
Y2_train = train2_df.iloc[:,-1].values
X2_valid = valid2_df.iloc[:,0:-1].values
Y2_valid = valid2_df.iloc[:,-1].values
X2_test = test2_df.iloc[:,:].values

# scalling and fitting data
scaler = StandardScaler()
scaler.fit(X2_train)

X2_train = scaler.transform(X2_train)
X2_valid = scaler.transform(X2_valid)
X2_test = scaler.transform(X2_test)

classifiers = [
    ("Random Forest", RandomForestClassifier()),
    ("K-Nearest Neighbors", KNeighborsClassifier(n_neighbors=5)),
    ("Support Vector Machine", SVC(kernel="linear")),
    ("Logistic Regression", LogisticRegression())
]

# Iterate over each classifier and perform cross-validation
for clf_name, clf in classifiers:
    cross_val_scores = cross_val_score(clf, X2_train, Y2_train, cv = 5)

    # Print the cross-validation scores for each classifier
    print(f"{clf_name} Cross-validation scores:", cross_val_scores)

    # Calculate and print the mean and standard deviation of the scores
    print(f"{clf_name} Mean accuracy:", cross_val_scores.mean())
    print(f"{clf_name} Standard deviation:", cross_val_scores.std())
    print("\n")

# Initialize and train a Support Vector Machine classifier
model = KNeighborsClassifier()
model.fit(X2_train, Y2_train)

# Make predictions on the test set
y_pred = model.predict(X2_valid)

print(classification_report(Y2_valid, y_pred))

# Create a SelectKBest instance with a scoring function (e.g., chi-squared)
selector = SelectKBest(score_func=f_classif, k=250)  # Select the top 2 features

# Fit and transform your data to select the best k features
X2_best_train = selector.fit_transform(X2_train, Y2_train)
X2_best_valid = selector.transform(X2_valid)
X2_best_test = selector.transform(X2_test)

model.fit(X2_best_train, Y2_train)

# Make predictions on the test set
y_pred = model.predict(X2_best_valid)

print(classification_report(Y2_valid, y_pred))

pca=PCA(0.95)
pca = pca.fit(X2_best_train)

x_2_train_pca=pca.fit_transform(X2_best_train)
x_2_valid_pca = pca.transform(X2_best_valid)
x_2_test_pca = pca.transform(X2_best_test)

model.fit(x_2_train_pca, Y2_train)

# Make predictions on the test set
y_pred = model.predict(x_2_valid_pca)

print(classification_report(Y2_valid, y_pred))

x_2_train_pca.shape

param_grid = {
    'n_neighbors': [1, 3, 5, 7, 9],  # Test different values of k
    'weights': ['uniform', 'distance'],  # Weighting strategy
    'p': [1, 2],  # Minkowski distance metric (1 for Manhattan, 2 for Euclidean)
}

# Create a GridSearchCV object with cross-validation
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)

# Fit the GridSearchCV object to the data to find the best hyperparameters
grid_search.fit(x_2_train_pca, Y2_train)

# Print the best hyperparameters and corresponding accuracy
best_params = grid_search.best_params_
best_accuracy = grid_search.best_score_
print("Best Hyperparameters:", best_params)
print("Best Accuracy:", best_accuracy)

best_model = grid_search.best_estimator_
y_pred = best_model.predict(x_2_valid_pca)
test_preds = best_model.predict(x_2_test_pca)

print(classification_report(Y2_valid, y_pred))

data_frame = pd.DataFrame(test_preds, columns=["label_2"])
data_frame.to_csv(f"190110V_2.csv",na_rep='')

